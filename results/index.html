<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta http-equiv="Content-Type" content="text/html; charset=windows-1252">

<script src="../files/head.js"></script>

<meta name="viewport" content="width=device-width, initial-scale=1">

<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

<meta name="keywords" content="Berkeley,Deep,Reinforcement,Learning,Computer Science,Machine,Artificial,Intelligence">

<article class="post-content">
  <meta name="twitter:title" content="Gamma-Models and Infinite-Horizon Prediction"/>
  <meta name="twitter:card" content="summary_large_image" />
  <meta name="twitter:image" content="https://people.eecs.berkeley.edu/~janner/gamma-models/images/twitter_card.png" />
<article class="post-content">

<title>Trajectory Transformer</title>
<link rel="stylesheet" href="../files/font.css">
<link rel="stylesheet" href="../files/main.css">

<link rel="stylesheet" type="text/css"
    href="https://cdn.rawgit.com/dreampulse/computer-modern-web-font/master/fonts.css">
<style>
body {
  font-family: "Computer Modern Serif", serif;
  font-size: 15pt;
}


* {padding:0;margin:0;box-sizing:border-box;}
#video {
  position: relative;
  padding-bottom: 45%; /* 16:9 */
  height: 0;
}
#video iframe {
  position: absolute;
  top: 0;
  left: 0;
  width: 80%;
  height: 100%;
  transform: translateX(12.5%);
}

</style>

  <style type="text/css">/**
 * Style sheet used by new LibX tooltip code
 */

/* We insert a <div> with libx-tooltip style under the body.
 * This will inherit body's style - we can't afford to inherit undesirable 
 * styles and we must redefine what we need.  OTOH, some things, e.g.
 * font-size, might be ok to be inherited to stay within the page's tone.
 */
.libx-tooltip {
    display: none;
    overflow: visible;
    padding: 5px;
    z-index: 100;
    background-color: #eee;
    color: #000;
    font-weight: normal;
    font-style: normal;
    text-align: left;
    border: 2px solid #666;
    border-radius: 5px;
    -webkit-border-radius: 5px;
    -moz-border-radius: 5px;
}

.libx-tooltip p {
    /* override default 1em margin to keep paragraphs inside a tooltip closer together. */
    margin: .2em;
}
</style><style type="text/css">/**
 * Style sheet used by LibX autolinking code
 */
.libx-autolink {
}

</style>

</head>

  <body>

    <div class="outercontainer">
      <div class="container">

        <div class="content project_title">
          <br>
          <h2>Trajectory Transformer Offline RL Results</h2>
        </div>

        <br><br>

        <center>
          <h4>Locomotion tasks</h4>
          <img width=65% src="images/tt_d4rl.png">
          <br>
          <br>
          <img width=60% src="images/bar.png">
          <br>
        </center>

        <p style="text-align: left; padding-top: 10px; padding-left: 5%; padding-right: 5%;">
          <font style="font-size: 0.9em;">
            Performance on the locomotion environments in the <a href="https://arxiv.org/abs/2004.07219">D4RL offline locomotion benchmark.</a> We compare two variants of the Trajectory Transformer (TT) &mdash; differing in how they discretize continuous inputs &mdash; with model-based, value-based, and recently proposed sequence-modeling algorithms.
          </font>
        </p>
        <br>

        <center>
          <h4>Compositionality in AntMaze</h4>
          <img width=60% src="images/tt_antmaze.png">
          <br>
        </center>
        <p style="text-align: left; padding-top: 15px; padding-left: 5%; padding-right: 5%;">
          <font style="font-size: 0.9em;">
            AntMaze tasks evaluate temporal compositionality because they require stitching together multiple zero-reward trajectories in the dataset to reach a designated goal.
            \(Q\)-guided Trajectory Transformer planning (TT\(_{\color{#999999}{(+Q)}}\)) outperforms all prior methods on all maze sizes and dataset compositions.
            In particular, it outperforms the IQL method from which we obtain the \(Q\)-function, underscoring that planning with a \(Q\)-function as a search heuristic can be less susceptible to errors in the \(Q\)-function than policy extraction.
            However, because the \(Q\)-guided planning procedure still benefits from the temporal compositionality of both dynamic programming and planning, it outperforms return-conditioning approaches that suffer due to the lack of complete demonstrations.
            <br>
            <br>
            <b>Abbreviations:</b> Trajectory Transformer (TT), <a href="https://arxiv.org/abs/2106.01345">Decision Transformer</a> (DT), <a href="https://arxiv.org/abs/2006.04779">conservative \(Q\)-learning</a> (CQL), <a href="https://arxiv.org/abs/2110.06169">implicit \(Q\)-learning</a> (IQL), <a href="https://arxiv.org/abs/2008.05556">model-based offline planning</a> (MBOP), <a href="https://arxiv.org/abs/1911.11361">behavior-regularized actor critic</a> (BRAC), behavior cloning (BC)
          </font>
        </p>
        <br>

      </div>
    </div> 

</body>

</html>
